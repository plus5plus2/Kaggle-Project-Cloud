{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load in training set...\n",
      "train_x: (1000L, 4096L)\n",
      "train_y: (1000L, 10L)\n"
     ]
    }
   ],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import load_npz\n",
    "\n",
    "train_x_path='train_x.npz'\n",
    "train_y_path='train_y_encoded.npz'\n",
    "test_x_path='test_x.npz'\n",
    "\n",
    "print 'load in training set...'\n",
    "train_x=np.array(load_npz(train_x_path).todense())\n",
    "train_y = np.array(load_npz(train_y_path).todense())\n",
    "\n",
    "#put random seed here\n",
    "selected_sample_index=np.random.choice(int(train_x.shape[0]),1000,replace=False)\n",
    "train_x=train_x[selected_sample_index,]\n",
    "train_y=train_y[selected_sample_index,]\n",
    "\n",
    "print 'train_x:',train_x.shape\n",
    "print 'train_y:',train_y.shape\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def loss(y,nn_output):\n",
    "    return 0.5*(sum(np.array(y)-np.array(nn_output))**2)\n",
    "\n",
    "class NN(object):\n",
    "    def __init__(self, num_neuron_per_layer,lr=0.01,batch=1,epoch=20):\n",
    "        self.lr=lr\n",
    "        self.batch=batch\n",
    "        self.epoch=epoch\n",
    "        self.num_layers = len(num_neuron_per_layer)\n",
    "        self.num_neuron_per_layer = num_neuron_per_layer#dummy neuron for the bias ignored\n",
    "        self.reset_weights_bias()\n",
    "\n",
    "    def reset_weights_bias(self):\n",
    "        self.weights=[]\n",
    "        self.bias=[]\n",
    "        for i in range(0,self.num_layers-1):\n",
    "            weight=np.random.randn(self.num_neuron_per_layer[i], self.num_neuron_per_layer[i+1])\n",
    "            self.weights.append(weight)\n",
    "            self.bias.append(np.random.randn(self.num_neuron_per_layer[i+1]))\n",
    "\n",
    "    #per sample\n",
    "    def feedforward(self, nn_input):\n",
    "        layer_output_his=[]\n",
    "        layer_output_his.append(nn_input)#to facilitate sgd, add the 0-layer input\n",
    "        layer_input=np.array(nn_input)\n",
    "        #layer_input.reshape(-1,1)\n",
    "        for w,b in zip(self.weights,self.bias):\n",
    "            layer_output = sigmoid(np.dot(w.T, layer_input)+b[0])\n",
    "            layer_output_his.append(layer_output)\n",
    "            layer_input=layer_output\n",
    "        return layer_output_his #layer_output_his[-1] is nn_output\n",
    "    \n",
    "    def gradient_descent(self,true_y,layer_output_his):\n",
    "        delta_weights=[]\n",
    "        delta_bs=[]\n",
    "        layer_output=layer_output_his[-1]\n",
    "        sig=np.dot(layer_output,np.ones(len(layer_output))-layer_output)\n",
    "        delta_base=np.dot(true_y-layer_output,sig)\n",
    "        layer_output_his=layer_output_his[:-1]\n",
    "        for w,layer_output in zip(reversed(self.weights),reversed(layer_output_his)):\n",
    "            delta_weight=-np.outer(layer_output,delta_base)\n",
    "            delta_weights.append(delta_weight)\n",
    "            delta_b=-delta_base\n",
    "            delta_bs.append(delta_b)\n",
    "            sig=np.dot(layer_output,np.ones(len(layer_output))-layer_output)\n",
    "            delta_base=-np.dot(w,np.multiply(sig,delta_base))\n",
    "        \n",
    "        return delta_weights,delta_bs\n",
    "    \n",
    "    def batch_gradient_descent(self, input_x,input_y):\n",
    "        while input_x.shape[0]>self.batch:\n",
    "            current_batch_index=np.random.choice(int(input_x.shape[0]),self.batch,replace=False)\n",
    "            batch_x=input_x[current_batch_index,]\n",
    "            batch_y=input_y[current_batch_index,]\n",
    "            input_x=np.delete(input_x, current_batch_index, axis=0)\n",
    "            input_y=np.delete(input_y, current_batch_index, axis=0)\n",
    "            acc_weights=0\n",
    "            acc_bias=0\n",
    "            for x,y in zip(batch_x,batch_y):\n",
    "                layer_output_his=self.feedforward(x)\n",
    "                delta_weights,delta_bs=self.gradient_descent(y,layer_output_his)\n",
    "                acc_weights=np.add(acc_weights,delta_weights)\n",
    "                acc_bias=np.add(acc_bias,delta_bs)\n",
    "            self.update_model(acc_weights,acc_bias)\n",
    "        if input_x.shape[0]>0:\n",
    "            for x,y in zip(input_x,input_y):\n",
    "                layer_output_his=self.feedforward(x)\n",
    "                delta_weights,delta_bs=self.gradient_descent(y,layer_output_his)\n",
    "                acc_weights=np.add(acc_weights,delta_weights)\n",
    "                acc_bias=np.add(acc_bias,delta_bs)\n",
    "            self.update_model(acc_weights,acc_bias)\n",
    "        \n",
    "        c_loss=0\n",
    "        for x,y in zip(input_x,input_y):\n",
    "            c_loss+=loss(y,self.feedforward(x)[-1])\n",
    "        print 'loss after this epoch = ',c_loss\n",
    "        \n",
    "    \n",
    "    def update_model(self,delta_weights,delta_bs):\n",
    "        for i in range(0,self.num_layers-1):\n",
    "            self.weights[i]=np.add(self.weights[i],np.multiply(delta_weights[-(i+1)],self.lr))\n",
    "            self.bias[i]=np.add(self.bias[i],np.multiply(delta_bs[-(i+1)],self.lr))\n",
    "    \n",
    "    def split_dataset(self,input_x,input_y,num_folder=3):\n",
    "        if len(input_x)!=len(input_y):\n",
    "            print 'len(input_x) = ',len(input_x),'; len(input_y) = ',len(input_y)\n",
    "            print 'len(input_x) must be equal to len(input_y).'\n",
    "            return None\n",
    "        return (np.linspace(0,len(input_y),num_folder+1,endpoint=True)).astype(int).tolist()[1:]\n",
    "        \n",
    "        \n",
    "    def fit_model(self,input_x,input_y,cv=False):\n",
    "        if cv:\n",
    "            split_index_end=self.split_dataset(input_x,input_y)\n",
    "            mse_his=[]\n",
    "            start=0\n",
    "            for end in split_index_end:\n",
    "                valid_x=input_x[start:end]\n",
    "                valid_y=input_y[start:end]\n",
    "                train_x=np.concatenate((input_x[0:start],input_x[end:]))\n",
    "                train_y=np.concatenate((input_y[0:start],input_y[end:]))\n",
    "                \n",
    "                self.reset_weights_bias()\n",
    "                \n",
    "                for i in range(0,self.epoch):\n",
    "                    print 'epoch ',i,' ...'\n",
    "                    self.batch_gradient_descent(input_x,input_y)\n",
    "                mse=0\n",
    "                for x,y in zip(valid_x,valid_y):\n",
    "                    mse+=loss(y,self.feedforward(x)[-1])\n",
    "                mse_his.append(float(mse)/len(valid_y))\n",
    "                start=end\n",
    "            return np.array(mse_his).mean()\n",
    "                        \n",
    "        else:\n",
    "            train_x=input_x\n",
    "            train_y=input_y\n",
    "            \n",
    "            \n",
    "            self.reset_weights_bias()\n",
    "                \n",
    "            for i in range(0,self.epoch):\n",
    "                print 'epoch ',i,' ...'\n",
    "                self.batch_gradient_descent(input_x,input_y)\n",
    "            \n",
    "            mse=0\n",
    "            for x,y in zip(train_x,train_y):\n",
    "                mse+=loss(y,self.feedforward(x)[-1])\n",
    "            return float(mse)/len(train_y)\n",
    "    \n",
    "    #per sample\n",
    "    def predict(self,x):\n",
    "        return np.argmax(self.feedforward(x)[-1])\n",
    "    \n",
    "def grid_search_model(input_x,input_y,lr_candidates=[0.01],nn_candidates=[[4096,100,10]]):\n",
    "    #an exmaple with lr\n",
    "    #init models\n",
    "    min_mse=float('inf')\n",
    "    min_lr=None\n",
    "    min_cc=None\n",
    "    c_mse=None\n",
    "    log=[]\n",
    "    for c_nn in nn_candidates:\n",
    "        for c_lr in lr_candidates:\n",
    "            \n",
    "            n=NN(num_neuron_per_layer=c_nn,lr=c_lr)\n",
    "            c_mse=n.fit_model(input_x,input_y,cv=True)\n",
    "            if min_mse>c_mse:\n",
    "                min_mse=c_mse\n",
    "                min_lr=c_lr\n",
    "                min_nn=c_nn\n",
    "            print 'best nn=',c_nn,'  c_lr=',c_lr, ' c_mse=',c_mse\n",
    "            c_log=[]\n",
    "            c_log.append(c_nn)\n",
    "            c_log.append(c_lr)\n",
    "            c_log.append(c_mse)\n",
    "            log.append(c_log)\n",
    "    return min_lr,min_nn,log\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0  ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\plus7_lu\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after this epoch =  2.4651928818959234e-32\n",
      "epoch  1  ...\n",
      "loss after this epoch =  2.9341457871076443e-33\n",
      "epoch  2  ...\n",
      "loss after this epoch =  6.162975952492458e-31\n",
      "epoch  3  ...\n",
      "loss after this epoch =  2.4651939579030644e-32\n",
      "epoch  4  ...\n",
      "loss after this epoch =  3.8288056753384205e-25\n",
      "epoch  5  ...\n",
      "loss after this epoch =  4.179908631351488e-45\n",
      "epoch  6  ...\n",
      "loss after this epoch =  1.2933354184813333e-42\n",
      "epoch  7  ...\n",
      "loss after this epoch =  4.899154922727052e-33\n",
      "epoch  8  ...\n",
      "loss after this epoch =  2.465190328882796e-32\n",
      "epoch  9  ...\n",
      "loss after this epoch =  2.25891376852995e-34\n",
      "epoch  10  ...\n",
      "loss after this epoch =  2.2755948460054664e-40\n",
      "epoch  11  ...\n",
      "loss after this epoch =  3.7831042181483464e-32\n",
      "epoch  12  ...\n",
      "loss after this epoch =  2.130820701144261e-28\n",
      "epoch  13  ...\n",
      "loss after this epoch =  0.0\n",
      "epoch  14  ...\n",
      "loss after this epoch =  1.3200771561389812e-33\n",
      "epoch  15  ...\n",
      "loss after this epoch =  3.7867021049184325e-32\n",
      "epoch  16  ...\n",
      "loss after this epoch =  3.0159427555298418e-30\n",
      "epoch  17  ...\n",
      "loss after this epoch =  4.979687891074971e-30\n",
      "epoch  18  ...\n",
      "loss after this epoch =  7.789194527483233e-32\n",
      "epoch  19  ...\n",
      "loss after this epoch =  6.162975951567463e-31\n",
      "epoch  20  ...\n",
      "loss after this epoch =  3.944304526107376e-31\n",
      "epoch  21  ...\n",
      "loss after this epoch =  2.7731637702770152e-30\n",
      "epoch  22  ...\n",
      "loss after this epoch =  3.7911776185694743e-32\n",
      "epoch  23  ...\n",
      "loss after this epoch =  7.69689069176504e-32\n",
      "epoch  24  ...\n",
      "loss after this epoch =  9.321822161642962e-29\n",
      "epoch  25  ...\n",
      "loss after this epoch =  6.265774518573451e-30\n",
      "epoch  26  ...\n",
      "loss after this epoch =  5.225967873802736e-36\n",
      "epoch  27  ...\n",
      "loss after this epoch =  4.6897622451273376e-32\n",
      "epoch  28  ...\n",
      "loss after this epoch =  2.554910751646774e-29\n",
      "epoch  29  ...\n",
      "loss after this epoch =  2.269382636627516e-31\n",
      "epoch  30  ...\n",
      "loss after this epoch =  9.32919799530177e-29\n",
      "epoch  31  ...\n",
      "loss after this epoch =  9.37326933281601e-29\n",
      "epoch  32  ...\n",
      "loss after this epoch =  2.9828803418639914e-30\n",
      "epoch  33  ...\n",
      "loss after this epoch =  2.4652177112745276e-32\n",
      "epoch  34  ...\n",
      "loss after this epoch =  9.847844094867583e-33\n",
      "epoch  35  ...\n",
      "loss after this epoch =  2.465198579623744e-32\n",
      "epoch  36  ...\n",
      "loss after this epoch =  2.7491186207227996e-30\n",
      "epoch  37  ...\n",
      "loss after this epoch =  7.733706503747362e-32\n",
      "epoch  38  ...\n",
      "loss after this epoch =  4.695968258819173e-32\n",
      "epoch  39  ...\n",
      "loss after this epoch =  2.7642426290211987e-30\n",
      "epoch  40  ...\n",
      "loss after this epoch =  6.162975951184956e-31\n",
      "epoch  41  ...\n",
      "loss after this epoch =  2.8928818191211e-40\n",
      "epoch  42  ...\n",
      "loss after this epoch =  2.2186712959340957e-31\n",
      "epoch  43  ...\n",
      "loss after this epoch =  2.760466810992205e-30\n",
      "epoch  44  ...\n",
      "loss after this epoch =  3.4845913347517835e-32\n",
      "epoch  45  ...\n",
      "loss after this epoch =  5.057146065351254e-30\n",
      "epoch  46  ...\n",
      "loss after this epoch =  6.31088737121133e-30\n",
      "epoch  47  ...\n",
      "loss after this epoch =  4.871808459883394e-30\n",
      "epoch  48  ...\n",
      "loss after this epoch =  1.3153198551207369e-33\n",
      "epoch  49  ...\n",
      "loss after this epoch =  2.4460851037673405e-27\n",
      "epoch  50  ...\n",
      "loss after this epoch =  2.4651938948319036e-32\n",
      "epoch  51  ...\n",
      "loss after this epoch =  9.964472820203783e-35\n",
      "epoch  52  ...\n",
      "loss after this epoch =  2.2186715326619565e-31\n",
      "epoch  53  ...\n",
      "loss after this epoch =  4.704762355723259e-32\n",
      "epoch  54  ...\n",
      "loss after this epoch =  9.551113355531353e-35\n",
      "epoch  55  ...\n",
      "loss after this epoch =  1.2716645894980706e-33\n",
      "epoch  56  ...\n",
      "loss after this epoch =  2.779463535510337e-29\n",
      "epoch  57  ...\n",
      "loss after this epoch =  9.549229174343526e-35\n",
      "epoch  58  ...\n",
      "loss after this epoch =  9.277990321530625e-28\n",
      "epoch  59  ...\n",
      "loss after this epoch =  6.279667954535035e-30\n",
      "epoch  60  ...\n",
      "loss after this epoch =  9.547235182507668e-35\n",
      "epoch  61  ...\n",
      "loss after this epoch =  8.474584168816661e-32\n",
      "epoch  62  ...\n",
      "loss after this epoch =  2.465190328815662e-32\n",
      "epoch  63  ...\n",
      "loss after this epoch =  2.284006578524833e-31\n",
      "epoch  64  ...\n",
      "loss after this epoch =  4.831773044478697e-30\n",
      "epoch  65  ...\n",
      "loss after this epoch =  2.7178723792168505e-30\n",
      "epoch  66  ...\n",
      "loss after this epoch =  9.277990321530625e-28\n",
      "epoch  67  ...\n",
      "loss after this epoch =  2.465190328815662e-32\n",
      "epoch  68  ...\n",
      "loss after this epoch =  6.284653488252973e-30\n",
      "epoch  69  ...\n",
      "loss after this epoch =  1.823260171008338e-28\n",
      "epoch  70  ...\n",
      "loss after this epoch =  5.101804855259352e-30\n",
      "epoch  71  ...\n",
      "loss after this epoch =  2.8185430532754585e-30\n",
      "epoch  72  ...\n",
      "loss after this epoch =  2.2186714925318054e-31\n",
      "epoch  73  ...\n",
      "loss after this epoch =  5.1326754601582015e-30\n",
      "epoch  74  ...\n",
      "loss after this epoch =  7.837423348774918e-32\n",
      "epoch  75  ...\n",
      "loss after this epoch =  1.0102341292237293e-34\n",
      "epoch  76  ...\n",
      "loss after this epoch =  3.2304840145245474e-27\n",
      "epoch  77  ...\n",
      "loss after this epoch =  1.2385081619568716e-29\n",
      "epoch  78  ...\n",
      "loss after this epoch =  2.2627861866992955e-31\n",
      "epoch  79  ...\n",
      "loss after this epoch =  1.068251424468999e-29\n",
      "epoch  80  ...\n",
      "loss after this epoch =  5.546678394602297e-30\n",
      "epoch  81  ...\n",
      "loss after this epoch =  6.162975950177517e-31\n",
      "epoch  82  ...\n",
      "loss after this epoch =  1.6040994163839504e-29\n",
      "epoch  83  ...\n",
      "loss after this epoch =  1.5407439555097887e-29\n",
      "epoch  84  ...\n",
      "loss after this epoch =  8.017975925460079e-50\n",
      "epoch  85  ...\n",
      "loss after this epoch =  1.2221368399451754e-33\n",
      "epoch  86  ...\n",
      "loss after this epoch =  1.220523502179978e-33\n",
      "epoch  87  ...\n",
      "loss after this epoch =  8.620524061884639e-28\n",
      "epoch  88  ...\n",
      "loss after this epoch =  1.4998217979265773e-28\n",
      "epoch  89  ...\n",
      "loss after this epoch =  2.4651922203443695e-32\n",
      "epoch  90  ...\n",
      "loss after this epoch =  3.749554490128622e-29\n",
      "epoch  91  ...\n",
      "loss after this epoch =  5.88720655413666e-31\n",
      "epoch  92  ...\n",
      "loss after this epoch =  3.8376982906685147e-32\n",
      "epoch  93  ...\n",
      "loss after this epoch =  2.982880297866951e-30\n",
      "epoch  94  ...\n",
      "loss after this epoch =  6.300995233611222e-30\n",
      "epoch  95  ...\n",
      "loss after this epoch =  9.518882680273316e-35\n",
      "epoch  96  ...\n",
      "loss after this epoch =  3.834637083061234e-25\n",
      "epoch  97  ...\n",
      "loss after this epoch =  7.911536146267466e-32\n",
      "epoch  98  ...\n",
      "loss after this epoch =  2.7180365757105422e-34\n",
      "epoch  99  ...\n",
      "loss after this epoch =  2.7570335643848632e-30\n",
      "epoch  100  ...\n",
      "loss after this epoch =  6.300799654449305e-30\n",
      "epoch  101  ...\n",
      "loss after this epoch =  2.2590150276246263e-31\n",
      "epoch  102  ...\n",
      "loss after this epoch =  1.0645537798128582e-31\n",
      "epoch  103  ...\n",
      "loss after this epoch =  2.4651922141256204e-32\n",
      "epoch  104  ...\n",
      "loss after this epoch =  2.4651930833249997e-32\n",
      "epoch  105  ...\n",
      "loss after this epoch =  3.8444981655863965e-32\n",
      "epoch  106  ...\n",
      "loss after this epoch =  4.459991467324367e-36\n",
      "epoch  107  ...\n",
      "loss after this epoch =  7.215459861363322e-42\n",
      "epoch  108  ...\n",
      "loss after this epoch =  6.310887241768095e-30\n",
      "epoch  109  ...\n",
      "loss after this epoch =  6.770046662056622e-29\n",
      "epoch  110  ...\n",
      "loss after this epoch =  1.7834129278759728e-34\n",
      "epoch  111  ...\n",
      "loss after this epoch =  2.465190328815662e-32\n",
      "epoch  112  ...\n",
      "loss after this epoch =  2.7168429307669817e-30\n",
      "epoch  113  ...\n",
      "loss after this epoch =  1.1921359255152777e-33\n",
      "epoch  114  ...\n",
      "loss after this epoch =  6.994255111618632e-31\n",
      "epoch  115  ...\n",
      "loss after this epoch =  2.2869139587291043e-31\n",
      "epoch  116  ...\n",
      "loss after this epoch =  3.84895815915946e-32\n",
      "epoch  117  ...\n",
      "loss after this epoch =  2.7178723783586778e-30\n",
      "epoch  118  ...\n",
      "loss after this epoch =  2.982880297866951e-30\n",
      "epoch  119  ...\n",
      "loss after this epoch =  1.1810268992017262e-42\n",
      "epoch  120  ...\n",
      "loss after this epoch =  6.3095522539801166e-30\n",
      "epoch  121  ...\n",
      "loss after this epoch =  7.620572876515303e-32\n",
      "epoch  122  ...\n",
      "loss after this epoch =  2.6879146594061107e-33\n",
      "epoch  123  ...\n",
      "loss after this epoch =  6.310299151533189e-30\n",
      "epoch  124  ...\n",
      "loss after this epoch =  2.465192207744687e-32\n",
      "epoch  125  ...\n",
      "loss after this epoch =  1.320161442723112e-33\n",
      "epoch  126  ...\n",
      "loss after this epoch =  7.636318908886123e-50\n",
      "epoch  127  ...\n",
      "loss after this epoch =  2.465190328815662e-32\n",
      "epoch  128  ...\n",
      "loss after this epoch =  2.711993282625797e-30\n",
      "epoch  129  ...\n",
      "loss after this epoch =  1.059381551592452e-32\n",
      "epoch  130  ...\n",
      "loss after this epoch =  0.0\n",
      "epoch  131  ...\n",
      "loss after this epoch =  2.4651903288782934e-32\n",
      "epoch  132  ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after this epoch =  6.310887241768133e-28\n",
      "epoch  133  ...\n",
      "loss after this epoch =  2.465216784010364e-32\n",
      "epoch  134  ...\n",
      "loss after this epoch =  2.5437521407065716e-23\n",
      "epoch  135  ...\n",
      "loss after this epoch =  2.697825050501297e-29\n",
      "epoch  136  ...\n",
      "loss after this epoch =  3.8557378657806667e-32\n",
      "epoch  137  ...\n",
      "loss after this epoch =  8.85442581293151e-24\n",
      "epoch  138  ...\n",
      "loss after this epoch =  3.849590896920073e-32\n",
      "epoch  139  ...\n",
      "loss after this epoch =  9.682926076049653e-29\n",
      "epoch  140  ...\n",
      "loss after this epoch =  6.640261325115453e-27\n",
      "epoch  141  ...\n",
      "loss after this epoch =  8.75933144442996e-29\n",
      "epoch  142  ...\n",
      "loss after this epoch =  4.762179169548435e-32\n",
      "epoch  143  ...\n",
      "loss after this epoch =  3.260214312430166e-30\n",
      "epoch  144  ...\n",
      "loss after this epoch =  5.2700653480602274e-30\n",
      "epoch  145  ...\n",
      "loss after this epoch =  9.860761315262648e-32\n",
      "epoch  146  ...\n",
      "loss after this epoch =  9.476191623967404e-29\n",
      "epoch  147  ...\n",
      "loss after this epoch =  2.4651907184148893e-32\n",
      "epoch  148  ...\n",
      "loss after this epoch =  1.1724018041118935e-42\n",
      "epoch  149  ...\n",
      "loss after this epoch =  2.465192342603542e-32\n",
      "epoch  150  ...\n",
      "loss after this epoch =  8.823324409241444e-42\n",
      "epoch  151  ...\n",
      "loss after this epoch =  4.319553099940503e-32\n",
      "epoch  152  ...\n",
      "loss after this epoch =  1.3107516179072858e-33\n",
      "epoch  153  ...\n",
      "loss after this epoch =  3.26021431225374e-30\n",
      "epoch  154  ...\n",
      "loss after this epoch =  6.164052392131852e-33\n",
      "epoch  155  ...\n",
      "loss after this epoch =  2.145342000460647e-29\n",
      "epoch  156  ...\n",
      "loss after this epoch =  2.6845922685268115e-29\n",
      "epoch  157  ...\n",
      "loss after this epoch =  4.758216102889651e-32\n",
      "epoch  158  ...\n",
      "loss after this epoch =  2.097369420754514e-28\n",
      "epoch  159  ...\n",
      "loss after this epoch =  6.310887241768095e-30\n",
      "epoch  160  ...\n",
      "loss after this epoch =  6.318587180860521e-30\n",
      "epoch  161  ...\n",
      "loss after this epoch =  8.643820896525365e-35\n",
      "epoch  162  ...\n",
      "loss after this epoch =  7.073064708621038e-42\n",
      "epoch  163  ...\n",
      "loss after this epoch =  6.286851639528108e-27\n",
      "epoch  164  ...\n",
      "loss after this epoch =  2.128077108648141e-40\n",
      "epoch  165  ...\n",
      "loss after this epoch =  3.709873516873451e-34\n",
      "epoch  166  ...\n",
      "loss after this epoch =  1.4998217978835108e-28\n",
      "epoch  167  ...\n",
      "loss after this epoch =  3.8646189603321866e-32\n",
      "epoch  168  ...\n",
      "loss after this epoch =  3.7405044493112584e-31\n",
      "epoch  169  ...\n",
      "loss after this epoch =  5.7992734404210745e-31\n",
      "epoch  170  ...\n",
      "loss after this epoch =  5.981805914392263e-31\n",
      "epoch  171  ...\n",
      "loss after this epoch =  3.6082897630741925e-34\n",
      "epoch  172  ...\n",
      "loss after this epoch =  6.310887366354478e-30\n",
      "epoch  173  ...\n",
      "loss after this epoch =  8.802776048972193e-32\n",
      "epoch  174  ...\n",
      "loss after this epoch =  2.465190328815662e-30\n",
      "epoch  175  ...\n",
      "loss after this epoch =  9.489724489426224e-35\n",
      "epoch  176  ...\n",
      "loss after this epoch =  4.772741722198346e-32\n",
      "epoch  177  ...\n",
      "loss after this epoch =  1.5407443506991073e-31\n",
      "epoch  178  ...\n",
      "loss after this epoch =  6.322107470751092e-30\n",
      "epoch  179  ...\n",
      "loss after this epoch =  1.209018585935812e-33\n",
      "epoch  180  ...\n",
      "loss after this epoch =  8.904084340114573e-29\n",
      "epoch  181  ...\n",
      "loss after this epoch =  1.0749543663208494e-32\n",
      "epoch  182  ...\n",
      "loss after this epoch =  2.4651937007284686e-32\n",
      "epoch  183  ...\n",
      "loss after this epoch =  6.328229319643248e-30\n",
      "epoch  184  ...\n",
      "loss after this epoch =  3.549874073494553e-30\n",
      "epoch  185  ...\n",
      "loss after this epoch =  2.465190328815662e-32\n",
      "epoch  186  ...\n",
      "loss after this epoch =  1.4998217960514487e-28\n",
      "epoch  187  ...\n",
      "loss after this epoch =  9.860765111692197e-32\n",
      "epoch  188  ...\n",
      "loss after this epoch =  9.86076477181729e-32\n",
      "epoch  189  ...\n",
      "loss after this epoch =  7.12181471102404e-29\n",
      "epoch  190  ...\n",
      "loss after this epoch =  5.889966839960267e-25\n",
      "epoch  191  ...\n",
      "loss after this epoch =  1.7611979743521007e-34\n",
      "epoch  192  ...\n",
      "loss after this epoch =  3.87120897141837e-32\n",
      "epoch  193  ...\n",
      "loss after this epoch =  5.1482749682118815e-33\n",
      "epoch  194  ...\n",
      "loss after this epoch =  2.115392170598772e-40\n",
      "epoch  195  ...\n",
      "loss after this epoch =  2.465190328815662e-32\n",
      "epoch  196  ...\n",
      "loss after this epoch =  9.860761315262648e-32\n",
      "epoch  197  ...\n",
      "loss after this epoch =  2.2510850649263775e-31\n",
      "epoch  198  ...\n",
      "loss after this epoch =  6.31088736587365e-30\n",
      "epoch  199  ...\n",
      "loss after this epoch =  9.860761315262648e-32\n",
      "epoch  200  ...\n",
      "loss after this epoch =  5.833541577580487e-32\n",
      "epoch  201  ...\n",
      "loss after this epoch =  7.325289509059602e-32\n",
      "epoch  202  ...\n",
      "loss after this epoch =  8.592372341361384e-33\n",
      "epoch  203  ...\n",
      "loss after this epoch =  9.476191623967404e-29\n",
      "epoch  204  ...\n",
      "loss after this epoch =  3.7183504285081203e-31\n",
      "epoch  205  ...\n",
      "loss after this epoch =  6.310887365742592e-30\n",
      "epoch  206  ...\n",
      "loss after this epoch =  4.6697037863278e-29\n",
      "epoch  207  ...\n",
      "loss after this epoch =  1.3037760226184817e-33\n",
      "epoch  208  ...\n",
      "loss after this epoch =  7.923172599450033e-28\n",
      "epoch  209  ...\n",
      "loss after this epoch =  6.162975948686743e-31\n",
      "epoch  210  ...\n",
      "loss after this epoch =  2.465190328815662e-30\n",
      "epoch  211  ...\n",
      "loss after this epoch =  3.7495545258362833e-29\n",
      "epoch  212  ...\n",
      "loss after this epoch =  7.220070160177433e-50\n",
      "epoch  213  ...\n",
      "loss after this epoch =  3.8760514987468036e-32\n",
      "epoch  214  ...\n",
      "loss after this epoch =  9.373886225321554e-28\n",
      "epoch  215  ...\n",
      "loss after this epoch =  2.7630693609891827e-21\n",
      "epoch  216  ...\n",
      "loss after this epoch =  6.310887365551315e-30\n",
      "epoch  217  ...\n",
      "loss after this epoch =  5.918921999160151e-29\n",
      "epoch  218  ...\n",
      "loss after this epoch =  7.975343581484275e-35\n",
      "epoch  219  ...\n",
      "loss after this epoch =  2.465190328815662e-32\n",
      "epoch  220  ...\n",
      "loss after this epoch =  8.089729196217451e-32\n",
      "epoch  221  ...\n",
      "loss after this epoch =  8.637201981104945e-35\n",
      "epoch  222  ...\n",
      "loss after this epoch =  9.860766872936e-32\n",
      "epoch  223  ...\n",
      "loss after this epoch =  9.476088574047671e-35\n",
      "epoch  224  ...\n",
      "loss after this epoch =  2.6170667024210565e-33\n",
      "epoch  225  ...\n",
      "loss after this epoch =  7.970527436881592e-31\n",
      "epoch  226  ...\n",
      "loss after this epoch =  2.369047905991851e-29\n",
      "epoch  227  ...\n",
      "loss after this epoch =  2.044169084960647e-16\n",
      "epoch  228  ...\n",
      "loss after this epoch =  3.8798228056238764e-32\n",
      "epoch  229  ...\n",
      "loss after this epoch =  3.6665247803373464e-29\n",
      "epoch  230  ...\n",
      "loss after this epoch =  5.756265786764315e-31\n",
      "epoch  231  ...\n",
      "loss after this epoch =  2.465193769178338e-32\n",
      "epoch  232  ...\n",
      "loss after this epoch =  4.787956285992929e-32\n",
      "epoch  233  ...\n",
      "loss after this epoch =  1.538611526427272e-33\n",
      "epoch  234  ...\n",
      "loss after this epoch =  2.183030341809091e-34\n",
      "epoch  235  ...\n",
      "loss after this epoch =  6.061364273925734e-31\n",
      "epoch  236  ...\n",
      "loss after this epoch =  4.7900035054435653e-32\n",
      "epoch  237  ...\n",
      "loss after this epoch =  9.445946106142834e-29\n",
      "epoch  238  ...\n",
      "loss after this epoch =  8.635433963066198e-35\n",
      "epoch  239  ...\n",
      "loss after this epoch =  3.1873846152743537e-31\n",
      "epoch  240  ...\n",
      "loss after this epoch =  8.874685183808135e-29\n",
      "epoch  241  ...\n",
      "loss after this epoch =  2.681909108285978e-30\n",
      "epoch  242  ...\n",
      "loss after this epoch =  3.549874073494553e-30\n",
      "epoch  243  ...\n",
      "loss after this epoch =  4.1439849807137196e-29\n",
      "epoch  244  ...\n",
      "loss after this epoch =  5.546681168827443e-32\n",
      "epoch  245  ...\n",
      "loss after this epoch =  3.424488366558417e-35\n",
      "epoch  246  ...\n",
      "loss after this epoch =  8.099725753554568e-32\n",
      "epoch  247  ...\n",
      "loss after this epoch =  2.176048754086308e-34\n",
      "epoch  248  ...\n",
      "loss after this epoch =  3.19488666619027e-29\n",
      "epoch  249  ...\n",
      "loss after this epoch =  2.10414177695463e-28\n",
      "epoch  250  ...\n",
      "loss after this epoch =  4.7924418486542007e-32\n",
      "epoch  251  ...\n",
      "loss after this epoch =  4.182007382440211e-30\n",
      "epoch  252  ...\n",
      "loss after this epoch =  2.465190328815662e-30\n",
      "epoch  253  ...\n",
      "loss after this epoch =  5.253829311275933e-28\n",
      "epoch  254  ...\n",
      "loss after this epoch =  8.833693400741985e-29\n",
      "epoch  255  ...\n",
      "loss after this epoch =  1.5407439555097887e-29\n",
      "epoch  256  ...\n",
      "loss after this epoch =  8.11718205457957e-32\n",
      "epoch  257  ...\n",
      "loss after this epoch =  5.1936876366521246e-27\n",
      "epoch  258  ...\n",
      "loss after this epoch =  6.310887364864567e-30\n",
      "epoch  259  ...\n",
      "loss after this epoch =  8.633304435220975e-35\n",
      "epoch  260  ...\n",
      "loss after this epoch =  2.465190328815662e-32\n",
      "epoch  261  ...\n",
      "loss after this epoch =  6.892080351111771e-42\n",
      "epoch  262  ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after this epoch =  1.0423037176374363e-35\n",
      "epoch  263  ...\n",
      "loss after this epoch =  5.546678243005223e-32\n",
      "epoch  264  ...\n",
      "loss after this epoch =  5.214917157840824e-33\n",
      "epoch  265  ...\n",
      "loss after this epoch =  1.3093602625743893e-33\n",
      "epoch  266  ...\n",
      "loss after this epoch =  2.6753385857011828e-30\n",
      "epoch  267  ...\n",
      "loss after this epoch =  8.133277174143005e-32\n",
      "epoch  268  ...\n",
      "loss after this epoch =  1.4213347806025276e-29\n",
      "epoch  269  ...\n",
      "loss after this epoch =  2.2186712959340957e-31\n",
      "epoch  270  ...\n",
      "loss after this epoch =  9.860766841613603e-32\n",
      "epoch  271  ...\n",
      "loss after this epoch =  1.185520900979987e-34\n",
      "epoch  272  ...\n",
      "loss after this epoch =  2.4651903684582168e-30\n",
      "epoch  273  ...\n",
      "loss after this epoch =  4.798010557626594e-32\n",
      "epoch  274  ...\n",
      "loss after this epoch =  1.7744265779228026e-33\n",
      "epoch  275  ...\n",
      "loss after this epoch =  2.465190328815662e-30\n",
      "epoch  276  ...\n",
      "loss after this epoch =  7.4070953121606285e-31\n",
      "epoch  277  ...\n",
      "loss after this epoch =  3.890110788881601e-32\n",
      "epoch  278  ...\n",
      "loss after this epoch =  1.3106588903127388e-33\n",
      "epoch  279  ...\n",
      "loss after this epoch =  2.4651910402592212e-30\n",
      "epoch  280  ...\n",
      "loss after this epoch =  2.465190328815662e-30\n",
      "epoch  281  ...\n",
      "loss after this epoch =  5.815291149827501e-30\n",
      "epoch  282  ...\n",
      "loss after this epoch =  9.716600707562724e-35\n",
      "epoch  283  ...\n",
      "loss after this epoch =  5.905303224808487e-31\n",
      "epoch  284  ...\n",
      "loss after this epoch =  1.0362839659490406e-31\n",
      "epoch  285  ...\n",
      "loss after this epoch =  5.929712813866913e-32\n",
      "epoch  286  ...\n",
      "loss after this epoch =  5.3920757659995024e-30\n",
      "epoch  287  ...\n",
      "loss after this epoch =  2.2186712959340957e-31\n",
      "epoch  288  ...\n",
      "loss after this epoch =  1.6436177917581578e-51\n",
      "epoch  289  ...\n",
      "loss after this epoch =  9.860761315262648e-32\n",
      "epoch  290  ...\n",
      "loss after this epoch =  5.8094116867644896e-21\n",
      "epoch  291  ...\n",
      "loss after this epoch =  4.3870014880215587e-41\n",
      "epoch  292  ...\n",
      "loss after this epoch =  4.8023701886224255e-32\n",
      "epoch  293  ...\n",
      "loss after this epoch =  8.495791763882242e-42\n",
      "epoch  294  ...\n",
      "loss after this epoch =  5.546692305745116e-32\n",
      "epoch  295  ...\n",
      "loss after this epoch =  4.195316866239984e-32\n",
      "epoch  296  ...\n",
      "loss after this epoch =  2.465313174078701e-32\n",
      "epoch  297  ...\n",
      "loss after this epoch =  5.711798874713298e-31\n",
      "epoch  298  ...\n",
      "loss after this epoch =  2.4651903683289155e-30\n",
      "epoch  299  ...\n",
      "loss after this epoch =  2.4651910414467796e-30\n",
      "epoch  300  ...\n",
      "loss after this epoch =  2.9124867310064744e-35\n",
      "epoch  301  ...\n",
      "loss after this epoch =  9.860764752493859e-32\n",
      "epoch  302  ...\n",
      "loss after this epoch =  2.465193741488083e-32\n",
      "epoch  303  ...\n",
      "loss after this epoch =  5.546692292820278e-32\n",
      "epoch  304  ...\n",
      "loss after this epoch =  2.1479797717109363e-34\n",
      "epoch  305  ...\n",
      "loss after this epoch =  1.5133662022705618e-28\n",
      "epoch  306  ...\n",
      "loss after this epoch =  5.4196347254098865e-30\n",
      "epoch  307  ...\n",
      "loss after this epoch =  4.409093527788303e-33\n",
      "epoch  308  ...\n",
      "loss after this epoch =  2.2132693001930723e-31\n",
      "epoch  309  ...\n",
      "loss after this epoch =  1.2152477551816837e-34\n",
      "epoch  310  ...\n",
      "loss after this epoch =  7.925164480872661e-35\n",
      "epoch  311  ...\n",
      "loss after this epoch =  6.431100670453117e-29\n",
      "epoch  312  ...\n",
      "loss after this epoch =  2.0631543962148934e-28\n",
      "epoch  313  ...\n",
      "loss after this epoch =  8.805557155871705e-29\n",
      "epoch  314  ...\n",
      "loss after this epoch =  0.0\n",
      "epoch  315  ...\n",
      "loss after this epoch =  1.1163126516196092e-42\n",
      "epoch  316  ...\n",
      "loss after this epoch =  3.8920937538582567e-32\n",
      "epoch  317  ...\n",
      "loss after this epoch =  5.427562731724089e-31\n",
      "epoch  318  ...\n",
      "loss after this epoch =  5.330357788481665e-25\n",
      "epoch  319  ...\n",
      "loss after this epoch =  5.696855974865006e-31\n",
      "epoch  320  ...\n",
      "loss after this epoch =  3.0373610041705695e-28\n",
      "epoch  321  ...\n",
      "loss after this epoch =  6.80303060382873e-42\n",
      "epoch  322  ...\n",
      "loss after this epoch =  6.517865976650994e-42\n",
      "epoch  323  ...\n",
      "loss after this epoch =  2.4839467375931007e-31\n",
      "epoch  324  ...\n",
      "loss after this epoch =  2.465190328815662e-32\n",
      "epoch  325  ...\n",
      "loss after this epoch =  1.0690835305776835e-31\n",
      "epoch  326  ...\n",
      "loss after this epoch =  7.976686870109529e-32\n",
      "epoch  327  ...\n",
      "loss after this epoch =  7.552533023353185e-29\n",
      "epoch  328  ...\n",
      "loss after this epoch =  1.5145222646625716e-28\n",
      "epoch  329  ...\n",
      "loss after this epoch =  2.465190328815662e-30\n",
      "epoch  330  ...\n",
      "loss after this epoch =  3.90113014280351e-32\n",
      "epoch  331  ...\n",
      "loss after this epoch =  5.83785061363193e-26\n",
      "epoch  332  ...\n",
      "loss after this epoch =  2.8626472779389433e-35\n",
      "epoch  333  ...\n",
      "loss after this epoch =  4.831773044541616e-30\n",
      "epoch  334  ...\n",
      "loss after this epoch =  2.218671485748802e-31\n",
      "epoch  335  ...\n",
      "loss after this epoch =  4.9582216661900443e-29\n",
      "epoch  336  ...\n",
      "loss after this epoch =  1.4700128420241284e-30\n",
      "epoch  337  ...\n",
      "loss after this epoch =  2.2695960736152653e-34\n",
      "epoch  338  ...\n",
      "loss after this epoch =  2.4651921703776237e-32\n",
      "epoch  339  ...\n",
      "loss after this epoch =  2.1322990720620822e-34\n",
      "epoch  340  ...\n",
      "loss after this epoch =  9.447943126462857e-35\n",
      "epoch  341  ...\n",
      "loss after this epoch =  1.4699271027496166e-30\n",
      "epoch  342  ...\n",
      "loss after this epoch =  5.546681145791229e-32\n",
      "epoch  343  ...\n",
      "loss after this epoch =  1.1426814397433136e-27\n",
      "epoch  344  ...\n",
      "loss after this epoch =  8.994439815948289e-45\n",
      "epoch  345  ...\n",
      "loss after this epoch =  9.860761315262648e-32\n",
      "epoch  346  ...\n",
      "loss after this epoch =  3.903744904154766e-32\n",
      "epoch  347  ...\n",
      "loss after this epoch =  2.0633540353124668e-40\n",
      "epoch  348  ...\n",
      "loss after this epoch =  2.5524863207358305e-33\n",
      "epoch  349  ...\n",
      "loss after this epoch =  6.31088724176813e-28\n",
      "epoch  350  ...\n",
      "loss after this epoch =  2.8819999035584706e-30\n",
      "epoch  351  ...\n",
      "loss after this epoch =  3.904873463869379e-32\n",
      "epoch  352  ...\n",
      "loss after this epoch =  6.310887363515831e-30\n",
      "epoch  353  ...\n",
      "loss after this epoch =  1.1615162761906e-27\n",
      "epoch  354  ...\n",
      "loss after this epoch =  2.0612107641500016e-40\n",
      "epoch  355  ...\n",
      "loss after this epoch =  5.546692223091006e-32\n",
      "epoch  356  ...\n",
      "loss after this epoch =  3.6338297070772043e-34\n",
      "epoch  357  ...\n",
      "loss after this epoch =  1.3097547594304767e-33\n",
      "epoch  358  ...\n",
      "loss after this epoch =  1.1777802857588054e-26\n",
      "epoch  359  ...\n",
      "loss after this epoch =  1.3083005421955167e-33\n",
      "epoch  360  ...\n",
      "loss after this epoch =  0.0\n",
      "epoch  361  ...\n",
      "loss after this epoch =  2.3843567379394356e-27\n",
      "epoch  362  ...\n",
      "loss after this epoch =  1.7394436962271305e-28\n",
      "epoch  363  ...\n",
      "loss after this epoch =  8.783085593108273e-29\n",
      "epoch  364  ...\n",
      "loss after this epoch =  5.546692211264643e-32\n",
      "epoch  365  ...\n",
      "loss after this epoch =  3.636168259920986e-31\n",
      "epoch  366  ...\n",
      "loss after this epoch =  2.465192949331566e-32\n",
      "epoch  367  ...\n",
      "loss after this epoch =  2.829533882308697e-28\n",
      "epoch  368  ...\n",
      "loss after this epoch =  8.398752770222244e-27\n",
      "epoch  369  ...\n",
      "loss after this epoch =  5.546681140476684e-32\n",
      "epoch  370  ...\n",
      "loss after this epoch =  5.302881763152817e-25\n",
      "epoch  371  ...\n",
      "loss after this epoch =  2.384356737940288e-27\n",
      "epoch  372  ...\n",
      "loss after this epoch =  2.2186816370077405e-29\n",
      "epoch  373  ...\n",
      "loss after this epoch =  4.59679080088673e-32\n",
      "epoch  374  ...\n",
      "loss after this epoch =  1.1962750704674418e-34\n",
      "epoch  375  ...\n",
      "loss after this epoch =  6.351969292968481e-30\n",
      "epoch  376  ...\n",
      "loss after this epoch =  4.224682988435729e-32\n",
      "epoch  377  ...\n",
      "loss after this epoch =  2.006561332024306e-33\n",
      "epoch  378  ...\n",
      "loss after this epoch =  6.162975947674568e-31\n",
      "epoch  379  ...\n",
      "loss after this epoch =  2.8223964075510407e-28\n",
      "epoch  380  ...\n",
      "loss after this epoch =  2.3004550268747976e-31\n",
      "epoch  381  ...\n",
      "loss after this epoch =  4.8215246517165223e-32\n",
      "epoch  382  ...\n",
      "loss after this epoch =  4.829755222273642e-32\n",
      "epoch  383  ...\n",
      "loss after this epoch =  2.4651921644506687e-32\n",
      "epoch  384  ...\n",
      "loss after this epoch =  3.296326943242089e-29\n",
      "epoch  385  ...\n",
      "loss after this epoch =  8.621332141827444e-35\n",
      "epoch  386  ...\n",
      "loss after this epoch =  2.5354072345479062e-33\n",
      "epoch  387  ...\n",
      "loss after this epoch =  6.1629758220692975e-31\n",
      "epoch  388  ...\n",
      "loss after this epoch =  4.4030398240197997e-41\n",
      "epoch  389  ...\n",
      "loss after this epoch =  0.0\n",
      "epoch  390  ...\n",
      "loss after this epoch =  5.546681135880403e-32\n",
      "epoch  391  ...\n",
      "loss after this epoch =  3.911989633486016e-32\n",
      "epoch  392  ...\n",
      "loss after this epoch =  9.261896351587621e-32\n",
      "epoch  393  ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after this epoch =  3.9065076819264084e-32\n",
      "epoch  394  ...\n",
      "loss after this epoch =  5.754506848153634e-29\n",
      "epoch  395  ...\n",
      "loss after this epoch =  6.354531117656451e-30\n",
      "epoch  396  ...\n",
      "loss after this epoch =  2.649563122687206e-30\n",
      "epoch  397  ...\n",
      "loss after this epoch =  1.7394437033485997e-28\n",
      "epoch  398  ...\n",
      "loss after this epoch =  2.577188900650954e-30\n",
      "epoch  399  ...\n",
      "loss after this epoch =  2.4651921624365293e-32\n",
      "epoch  400  ...\n",
      "loss after this epoch =  6.701809125004231e-50\n",
      "epoch  401  ...\n",
      "loss after this epoch =  8.031454826589676e-33\n",
      "epoch  402  ...\n",
      "loss after this epoch =  0.0\n",
      "epoch  403  ...\n",
      "loss after this epoch =  1.0953676779588508e-42\n",
      "epoch  404  ...\n",
      "loss after this epoch =  0.0\n",
      "epoch  405  ...\n",
      "loss after this epoch =  2.2186712959340957e-31\n",
      "epoch  406  ...\n",
      "loss after this epoch =  2.4651921615699034e-32\n",
      "epoch  407  ...\n",
      "loss after this epoch =  3.549874073494553e-30\n",
      "epoch  408  ...\n",
      "loss after this epoch =  1.0983600042368428e-42\n",
      "epoch  409  ...\n",
      "loss after this epoch =  2.9828803493760084e-30\n",
      "epoch  410  ...\n",
      "loss after this epoch =  8.262272237314453e-32\n",
      "epoch  411  ...\n",
      "loss after this epoch =  2.2158841339046662e-44\n",
      "epoch  412  ...\n",
      "loss after this epoch =  9.498723964550591e-33\n",
      "epoch  413  ...\n",
      "loss after this epoch =  2.0102375112422378e-30\n",
      "epoch  414  ...\n",
      "loss after this epoch =  3.152957085687378e-29\n",
      "epoch  415  ...\n",
      "loss after this epoch =  5.525935417298151e-30\n",
      "epoch  416  ...\n",
      "loss after this epoch =  3.944304526107089e-31\n",
      "epoch  417  ...\n",
      "loss after this epoch =  1.2184093499798253e-22\n",
      "epoch  418  ...\n",
      "loss after this epoch =  4.8317730445409016e-30\n",
      "epoch  419  ...\n",
      "loss after this epoch =  7.448879193847337e-27\n",
      "epoch  420  ...\n",
      "loss after this epoch =  9.860764736424195e-32\n",
      "epoch  421  ...\n",
      "loss after this epoch =  4.595364001571862e-32\n",
      "epoch  422  ...\n",
      "loss after this epoch =  3.917934377178051e-32\n",
      "epoch  423  ...\n",
      "loss after this epoch =  1.7394437084541605e-28\n",
      "epoch  424  ...\n",
      "loss after this epoch =  2.257081396227056e-24\n",
      "epoch  425  ...\n",
      "loss after this epoch =  2.5532335637115195e-33\n",
      "epoch  426  ...\n",
      "loss after this epoch =  2.237762462517617e-31\n",
      "epoch  427  ...\n",
      "loss after this epoch =  2.37827737012846e-27\n",
      "epoch  428  ...\n",
      "loss after this epoch =  9.763372558828293e-32\n",
      "epoch  429  ...\n",
      "loss after this epoch =  2.641748082467664e-30\n",
      "epoch  430  ...\n",
      "loss after this epoch =  8.777930112786763e-29\n",
      "epoch  431  ...\n",
      "loss after this epoch =  3.498921470065271e-34\n",
      "epoch  432  ...\n",
      "loss after this epoch =  6.163025422461637e-33\n",
      "epoch  433  ...\n",
      "loss after this epoch =  1.1715445608696689e-36\n",
      "epoch  434  ...\n",
      "loss after this epoch =  5.546681127658339e-32\n",
      "epoch  435  ...\n",
      "loss after this epoch =  2.465192158067961e-32\n",
      "epoch  436  ...\n",
      "loss after this epoch =  4.992010415864412e-31\n",
      "epoch  437  ...\n",
      "loss after this epoch =  2.4651906485284527e-32\n",
      "epoch  438  ...\n",
      "loss after this epoch =  8.119813043381488e-29\n",
      "epoch  439  ...\n",
      "loss after this epoch =  2.2376184824305376e-31\n",
      "epoch  440  ...\n",
      "loss after this epoch =  8.009403418151299e-29\n",
      "epoch  441  ...\n",
      "loss after this epoch =  1.3054559938243362e-29\n",
      "epoch  442  ...\n",
      "loss after this epoch =  5.548002786264999e-30\n",
      "epoch  443  ...\n",
      "loss after this epoch =  9.621746505265363e-29\n",
      "epoch  444  ...\n",
      "loss after this epoch =  2.8223964075505627e-28\n",
      "epoch  445  ...\n",
      "loss after this epoch =  1.3016528927111378e-33\n",
      "epoch  446  ...\n",
      "loss after this epoch =  1.2033910468316082e-34\n",
      "epoch  447  ...\n",
      "loss after this epoch =  2.4651903293831495e-32\n",
      "epoch  448  ...\n",
      "loss after this epoch =  5.5466782545023136e-30\n",
      "epoch  449  ...\n",
      "loss after this epoch =  2.41613304138059e-28\n",
      "epoch  450  ...\n",
      "loss after this epoch =  1.5237012922312239e-26\n",
      "epoch  451  ...\n",
      "loss after this epoch =  2.6393133510917873e-30\n",
      "epoch  452  ...\n",
      "loss after this epoch =  9.096176975995232e-32\n",
      "epoch  453  ...\n",
      "loss after this epoch =  2.636074682548829e-30\n",
      "epoch  454  ...\n",
      "loss after this epoch =  8.295173301263483e-32\n",
      "epoch  455  ...\n",
      "loss after this epoch =  2.5059978254718216e-33\n",
      "epoch  456  ...\n",
      "loss after this epoch =  2.465190328815662e-32\n",
      "epoch  457  ...\n",
      "loss after this epoch =  1.0012398355098438e-29\n",
      "epoch  458  ...\n",
      "loss after this epoch =  2.2366180931248196e-31\n",
      "epoch  459  ...\n",
      "loss after this epoch =  4.8366425386704905e-32\n",
      "epoch  460  ...\n",
      "loss after this epoch =  2.4651937021751856e-32\n",
      "epoch  461  ...\n",
      "loss after this epoch =  8.38574545977744e-24\n",
      "epoch  462  ...\n",
      "loss after this epoch =  2.376696158993415e-27\n",
      "epoch  463  ...\n",
      "loss after this epoch =  6.162975822049726e-31\n",
      "epoch  464  ...\n",
      "loss after this epoch =  4.7819181977099805e-26\n",
      "epoch  465  ...\n",
      "loss after this epoch =  2.982880297866951e-30\n",
      "epoch  466  ...\n",
      "loss after this epoch =  6.305119078362726e-42\n",
      "epoch  467  ...\n",
      "loss after this epoch =  2.0310414592101163e-40\n",
      "epoch  468  ...\n",
      "loss after this epoch =  2.1233561385082547e-25\n",
      "epoch  469  ...\n",
      "loss after this epoch =  5.399752921505592e-28\n",
      "epoch  470  ...\n",
      "loss after this epoch =  9.860764999977776e-32\n",
      "epoch  471  ...\n",
      "loss after this epoch =  5.546681120896968e-32\n",
      "epoch  472  ...\n",
      "loss after this epoch =  5.612544942684164e-31\n",
      "epoch  473  ...\n",
      "loss after this epoch =  9.761070911002551e-32\n",
      "epoch  474  ...\n",
      "loss after this epoch =  5.229349661571172e-30\n",
      "epoch  475  ...\n",
      "loss after this epoch =  2.4651903294380344e-32\n",
      "epoch  476  ...\n",
      "loss after this epoch =  8.61331277618344e-35\n",
      "epoch  477  ...\n",
      "loss after this epoch =  2.6346339290036853e-30\n",
      "epoch  478  ...\n",
      "loss after this epoch =  2.027998956099867e-40\n",
      "epoch  479  ...\n",
      "loss after this epoch =  5.6414491658493435e-33\n",
      "epoch  480  ...\n",
      "loss after this epoch =  2.6341126252055152e-30\n",
      "epoch  481  ...\n",
      "loss after this epoch =  2.8329549874710964e-33\n",
      "epoch  482  ...\n",
      "loss after this epoch =  4.992010415864343e-31\n",
      "epoch  483  ...\n",
      "loss after this epoch =  0.0\n",
      "epoch  484  ...\n",
      "loss after this epoch =  2.349681835725159e-47\n",
      "epoch  485  ...\n",
      "loss after this epoch =  8.827154672501909e-54\n",
      "epoch  486  ...\n",
      "loss after this epoch =  6.162975947167725e-31\n",
      "epoch  487  ...\n",
      "loss after this epoch =  2.0259950885441616e-40\n",
      "epoch  488  ...\n",
      "loss after this epoch =  2.4652420436986046e-32\n",
      "epoch  489  ...\n",
      "loss after this epoch =  2.465193135030794e-32\n",
      "epoch  490  ...\n",
      "loss after this epoch =  2.7628470802681416e-40\n",
      "epoch  491  ...\n",
      "loss after this epoch =  5.793059325942032e-31\n",
      "epoch  492  ...\n",
      "loss after this epoch =  1.0388394238139902e-33\n",
      "epoch  493  ...\n",
      "loss after this epoch =  3.549874073494553e-30\n",
      "epoch  494  ...\n",
      "loss after this epoch =  8.551752203147108e-32\n",
      "epoch  495  ...\n",
      "loss after this epoch =  1.974025936084747e-40\n",
      "epoch  496  ...\n",
      "loss after this epoch =  2.2186712959340957e-31\n",
      "epoch  497  ...\n",
      "loss after this epoch =  9.220294789264958e-35\n",
      "epoch  498  ...\n",
      "loss after this epoch =  3.944304526105066e-31\n",
      "epoch  499  ...\n",
      "loss after this epoch =  6.579911849915088e-42\n"
     ]
    }
   ],
   "source": [
    "#build final model configured with best hyperparameter on whole training data\n",
    "n=NN(num_neuron_per_layer=[4096, 128, 1024, 10],lr=0.01,batch=1,epoch=500)\n",
    "f_mse=n.fit_model(train_x,train_y,cv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\plus7_lu\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.085\n"
     ]
    }
   ],
   "source": [
    "#print training accuracy\n",
    "acc=0\n",
    "for x,y in zip(train_x,train_y):\n",
    "    predict_y=n.predict(x)\n",
    "    if predict_y==np.argmax(y):\n",
    "        acc+=1\n",
    "print float(acc)/len(train_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#load in test data\\nprint 'load in dummy test set...'\\ntest_x=train_x[100:]\\ntest_y=train_y[100:]\\nprint 'test_x:',test_x.shape\\nprint 'test_y:',test_y.shape\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#load in test data\n",
    "print 'load in dummy test set...'\n",
    "test_x=train_x[100:]\n",
    "test_y=train_y[100:]\n",
    "print 'test_x:',test_x.shape\n",
    "print 'test_y:',test_y.shape\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#print testing accuracy\\nacc=0\\nfor x,y in zip(test_x,test_y):\\n    predict_y=n.predict(x)\\n    if predict_y==np.argmax(y):\\n        acc+=1\\nprint float(acc)/len(test_x)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#print testing accuracy\n",
    "acc=0\n",
    "for x,y in zip(test_x,test_y):\n",
    "    predict_y=n.predict(x)\n",
    "    if predict_y==np.argmax(y):\n",
    "        acc+=1\n",
    "print float(acc)/len(test_x)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncurrent_batch_index=np.random.choice(int(train_x.shape[0]),1,replace=False)\\nprint current_batch_index\\nbatch_x=train_x[current_batch_index,]\\nprint batch_x\\nbatch_y=train_y[current_batch_index,]\\nprint batch_y\\n#input_x=np.delete(train_x, current_batch_index, axis=0)\\n#input_y=np.delete(train_y, current_batch_index, axis=0)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "current_batch_index=np.random.choice(int(train_x.shape[0]),1,replace=False)\n",
    "print current_batch_index\n",
    "batch_x=train_x[current_batch_index,]\n",
    "print batch_x\n",
    "batch_y=train_y[current_batch_index,]\n",
    "print batch_y\n",
    "#input_x=np.delete(train_x, current_batch_index, axis=0)\n",
    "#input_y=np.delete(train_y, current_batch_index, axis=0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "[4096, 128, 1024, 10]\n",
      "1\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "#print best_model\n",
    "print n.lr\n",
    "print n.num_neuron_per_layer\n",
    "print n.batch\n",
    "print n.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=pd.read_csv('tuning_log.csv',header=None)\n",
    "r.columns =['nn','lr','loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       nn     lr          loss\n",
      "0         [4096, 128, 10]  0.001  1.355360e-01\n",
      "1         [4096, 128, 10]  0.010  2.687485e+01\n",
      "2         [4096, 128, 10]  0.100  4.049493e+01\n",
      "3         [4096, 128, 10]  1.000  4.049958e+01\n",
      "4         [4096, 512, 10]  0.001  1.422742e-01\n",
      "5         [4096, 512, 10]  0.010  2.167254e-01\n",
      "6         [4096, 512, 10]  0.100  4.046450e+01\n",
      "7         [4096, 512, 10]  1.000  4.049966e+01\n",
      "8        [4096, 1024, 10]  0.001  1.919019e-01\n",
      "9        [4096, 1024, 10]  0.010  2.841949e-01\n",
      "10       [4096, 1024, 10]  0.100  1.367679e+01\n",
      "11       [4096, 1024, 10]  1.000  4.048387e+01\n",
      "12       [4096, 2048, 10]  0.001  2.700839e-01\n",
      "13       [4096, 2048, 10]  0.010  3.125728e-01\n",
      "14       [4096, 2048, 10]  0.100  3.296885e-01\n",
      "15       [4096, 2048, 10]  1.000  4.039636e+01\n",
      "16   [4096, 128, 128, 10]  0.001  1.096494e+01\n",
      "17   [4096, 128, 128, 10]  0.010  4.022652e+01\n",
      "18   [4096, 128, 128, 10]  0.100  4.049525e+01\n",
      "19   [4096, 128, 128, 10]  1.000  4.049951e+01\n",
      "20   [4096, 128, 512, 10]  0.001  1.213055e-01\n",
      "21   [4096, 128, 512, 10]  0.010  5.024346e-06\n",
      "22   [4096, 128, 512, 10]  0.100  3.333322e-01\n",
      "23   [4096, 128, 512, 10]  1.000  1.037625e+01\n",
      "24  [4096, 128, 1024, 10]  0.001  5.776423e-05\n",
      "25  [4096, 128, 1024, 10]  0.010  2.213244e-13\n",
      "26  [4096, 128, 1024, 10]  0.100  2.066818e-10\n",
      "27  [4096, 128, 1024, 10]  1.000  2.849966e+01\n",
      "28   [4096, 512, 128, 10]  0.001  1.236054e+01\n",
      "29   [4096, 512, 128, 10]  0.010  2.689979e+01\n",
      "30   [4096, 512, 128, 10]  0.100  4.049490e+01\n",
      "31   [4096, 512, 128, 10]  1.000  1.433312e+01\n",
      "32   [4096, 512, 512, 10]  0.001  2.838566e-01\n",
      "33   [4096, 512, 512, 10]  0.010  1.730702e-01\n",
      "34   [4096, 512, 512, 10]  0.100  1.850274e-01\n",
      "35   [4096, 512, 512, 10]  1.000  4.260111e+00\n",
      "36  [4096, 512, 1024, 10]  0.001  1.885949e-01\n",
      "37  [4096, 512, 1024, 10]  0.010  1.539755e-09\n",
      "38  [4096, 512, 1024, 10]  0.100  2.725899e-12\n",
      "39  [4096, 512, 1024, 10]  1.000  1.654306e+01\n"
     ]
    }
   ],
   "source": [
    "print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[4096, 1024, 10]': Int64Index([8, 9, 10, 11], dtype='int64'),\n",
       " '[4096, 128, 1024, 10]': Int64Index([24, 25, 26, 27], dtype='int64'),\n",
       " '[4096, 128, 10]': Int64Index([0, 1, 2, 3], dtype='int64'),\n",
       " '[4096, 128, 128, 10]': Int64Index([16, 17, 18, 19], dtype='int64'),\n",
       " '[4096, 128, 512, 10]': Int64Index([20, 21, 22, 23], dtype='int64'),\n",
       " '[4096, 2048, 10]': Int64Index([12, 13, 14, 15], dtype='int64'),\n",
       " '[4096, 512, 1024, 10]': Int64Index([36, 37, 38, 39], dtype='int64'),\n",
       " '[4096, 512, 10]': Int64Index([4, 5, 6, 7], dtype='int64'),\n",
       " '[4096, 512, 128, 10]': Int64Index([28, 29, 30, 31], dtype='int64'),\n",
       " '[4096, 512, 512, 10]': Int64Index([32, 33, 34, 35], dtype='int64')}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.groupby('nn').groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       nn   lr       loss\n",
      "3         [4096, 128, 10]  1.0  40.499583\n",
      "7         [4096, 512, 10]  1.0  40.499656\n",
      "11       [4096, 1024, 10]  1.0  40.483873\n",
      "15       [4096, 2048, 10]  1.0  40.396363\n",
      "19   [4096, 128, 128, 10]  1.0  40.499512\n",
      "23   [4096, 128, 512, 10]  1.0  10.376253\n",
      "27  [4096, 128, 1024, 10]  1.0  28.499661\n",
      "31   [4096, 512, 128, 10]  1.0  14.333116\n",
      "35   [4096, 512, 512, 10]  1.0   4.260111\n",
      "39  [4096, 512, 1024, 10]  1.0  16.543065\n",
      "                       nn     lr       loss\n",
      "0         [4096, 128, 10]  0.001   0.135536\n",
      "4         [4096, 512, 10]  0.001   0.142274\n",
      "8        [4096, 1024, 10]  0.001   0.191902\n",
      "12       [4096, 2048, 10]  0.001   0.270084\n",
      "16   [4096, 128, 128, 10]  0.001  10.964940\n",
      "20   [4096, 128, 512, 10]  0.001   0.121306\n",
      "24  [4096, 128, 1024, 10]  0.001   0.000058\n",
      "28   [4096, 512, 128, 10]  0.001  12.360544\n",
      "32   [4096, 512, 512, 10]  0.001   0.283857\n",
      "36  [4096, 512, 1024, 10]  0.001   0.188595\n",
      "                       nn    lr          loss\n",
      "1         [4096, 128, 10]  0.01  2.687485e+01\n",
      "5         [4096, 512, 10]  0.01  2.167254e-01\n",
      "9        [4096, 1024, 10]  0.01  2.841949e-01\n",
      "13       [4096, 2048, 10]  0.01  3.125728e-01\n",
      "17   [4096, 128, 128, 10]  0.01  4.022652e+01\n",
      "21   [4096, 128, 512, 10]  0.01  5.024346e-06\n",
      "25  [4096, 128, 1024, 10]  0.01  2.213244e-13\n",
      "29   [4096, 512, 128, 10]  0.01  2.689979e+01\n",
      "33   [4096, 512, 512, 10]  0.01  1.730702e-01\n",
      "37  [4096, 512, 1024, 10]  0.01  1.539755e-09\n",
      "                       nn   lr          loss\n",
      "2         [4096, 128, 10]  0.1  4.049493e+01\n",
      "6         [4096, 512, 10]  0.1  4.046450e+01\n",
      "10       [4096, 1024, 10]  0.1  1.367679e+01\n",
      "14       [4096, 2048, 10]  0.1  3.296885e-01\n",
      "18   [4096, 128, 128, 10]  0.1  4.049525e+01\n",
      "22   [4096, 128, 512, 10]  0.1  3.333322e-01\n",
      "26  [4096, 128, 1024, 10]  0.1  2.066818e-10\n",
      "30   [4096, 512, 128, 10]  0.1  4.049490e+01\n",
      "34   [4096, 512, 512, 10]  0.1  1.850274e-01\n",
      "38  [4096, 512, 1024, 10]  0.1  2.725899e-12\n"
     ]
    }
   ],
   "source": [
    "for lr in r.groupby('lr').groups:\n",
    "    print r.groupby('lr').get_group(lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.46590946]\n",
      " [ 9.49877288]\n",
      " [17.64744095]\n",
      " [27.63911922]]\n"
     ]
    }
   ],
   "source": [
    "t_lr=r.groupby(['lr']).mean()\n",
    "print t_lr.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xd5da550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# linear\\nplt.subplot(2,2,1)\\nc_nn='[4096, 128, 10]'\\nm1=r.groupby('nn').get_group(c_nn)\\nplt.plot(m1.lr, m1.loss,'-o', mfc='red')\\nplt.title(c_nn)\\nplt.grid(True)\\n\\n\\n# log\\nplt.subplot(222)\\nplt.plot([1,2,3], [1,2,3])\\n\\nplt.grid(True)\\n\\n\\n# symmetric log\\nplt.subplot(223)\\nplt.plot([1,2,3], [1,2,3])\\n\\nplt.grid(True)\\n\\n# logit\\nplt.subplot(224)\\nplt.plot([1,2,3], [1,2,3])\\nplt.grid(True)\\n\\n\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(1,(10,4))\n",
    "for index,nn in enumerate(r.groupby('nn').groups):\n",
    "    plt.subplot(2,5,index+1)\n",
    "    c_nn=str(nn)\n",
    "    m1=r.groupby('nn').get_group(c_nn)\n",
    "    plt.plot(m1.lr, m1.loss,'-o', mfc='red')\n",
    "    plt.title(c_nn)\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      nn     lr       loss\n",
      "20  [4096, 128, 512, 10]  0.001   0.121306\n",
      "21  [4096, 128, 512, 10]  0.010   0.000005\n",
      "22  [4096, 128, 512, 10]  0.100   0.333332\n",
      "23  [4096, 128, 512, 10]  1.000  10.376253\n",
      "                      nn     lr       loss\n",
      "28  [4096, 512, 128, 10]  0.001  12.360544\n",
      "29  [4096, 512, 128, 10]  0.010  26.899795\n",
      "30  [4096, 512, 128, 10]  0.100  40.494896\n",
      "31  [4096, 512, 128, 10]  1.000  14.333116\n",
      "                nn     lr       loss\n",
      "0  [4096, 128, 10]  0.001   0.135536\n",
      "1  [4096, 128, 10]  0.010  26.874850\n",
      "2  [4096, 128, 10]  0.100  40.494930\n",
      "3  [4096, 128, 10]  1.000  40.499583\n",
      "                       nn     lr          loss\n",
      "24  [4096, 128, 1024, 10]  0.001  5.776423e-05\n",
      "25  [4096, 128, 1024, 10]  0.010  2.213244e-13\n",
      "26  [4096, 128, 1024, 10]  0.100  2.066818e-10\n",
      "27  [4096, 128, 1024, 10]  1.000  2.849966e+01\n",
      "                nn     lr       loss\n",
      "4  [4096, 512, 10]  0.001   0.142274\n",
      "5  [4096, 512, 10]  0.010   0.216725\n",
      "6  [4096, 512, 10]  0.100  40.464496\n",
      "7  [4096, 512, 10]  1.000  40.499656\n",
      "                      nn     lr      loss\n",
      "32  [4096, 512, 512, 10]  0.001  0.283857\n",
      "33  [4096, 512, 512, 10]  0.010  0.173070\n",
      "34  [4096, 512, 512, 10]  0.100  0.185027\n",
      "35  [4096, 512, 512, 10]  1.000  4.260111\n",
      "                  nn     lr       loss\n",
      "12  [4096, 2048, 10]  0.001   0.270084\n",
      "13  [4096, 2048, 10]  0.010   0.312573\n",
      "14  [4096, 2048, 10]  0.100   0.329688\n",
      "15  [4096, 2048, 10]  1.000  40.396363\n",
      "                  nn     lr       loss\n",
      "8   [4096, 1024, 10]  0.001   0.191902\n",
      "9   [4096, 1024, 10]  0.010   0.284195\n",
      "10  [4096, 1024, 10]  0.100  13.676791\n",
      "11  [4096, 1024, 10]  1.000  40.483873\n",
      "                       nn     lr          loss\n",
      "36  [4096, 512, 1024, 10]  0.001  1.885949e-01\n",
      "37  [4096, 512, 1024, 10]  0.010  1.539755e-09\n",
      "38  [4096, 512, 1024, 10]  0.100  2.725899e-12\n",
      "39  [4096, 512, 1024, 10]  1.000  1.654306e+01\n",
      "                      nn     lr       loss\n",
      "16  [4096, 128, 128, 10]  0.001  10.964940\n",
      "17  [4096, 128, 128, 10]  0.010  40.226516\n",
      "18  [4096, 128, 128, 10]  0.100  40.495248\n",
      "19  [4096, 128, 128, 10]  1.000  40.499512\n"
     ]
    }
   ],
   "source": [
    "for nn in r.groupby('nn').groups:\n",
    "    print r.groupby('nn').get_group(str(nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['[4096, 128, 10]', 0.01, 26.874850207638772],\n",
       "       ['[4096, 512, 10]', 0.01, 0.21672540728369566],\n",
       "       ['[4096, 1024, 10]', 0.01, 0.2841949474052728],\n",
       "       ['[4096, 2048, 10]', 0.01, 0.31257279024200785],\n",
       "       ['[4096, 128, 128, 10]', 0.01, 40.226515668608094],\n",
       "       ['[4096, 128, 512, 10]', 0.01, 5.024346128435502e-06],\n",
       "       ['[4096, 128, 1024, 10]', 0.01, 2.2132435050358262e-13],\n",
       "       ['[4096, 512, 128, 10]', 0.01, 26.89979455227707],\n",
       "       ['[4096, 512, 512, 10]', 0.01, 0.17307022456274088],\n",
       "       ['[4096, 512, 1024, 10]', 0.01, 1.5397547232383618e-09]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.groupby('lr').get_group(0.01).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in real test data\n",
    "print 'load in real test set...'\n",
    "test_x=np.array(load_npz(test_x_path).todense())\n",
    "result=[]\n",
    "print 'test_x:',test_x.shape\n",
    "for index, x in enumerate(test_x):\n",
    "    predict_y=n.predict(x)\n",
    "    result.append([index,predict_y])\n",
    "result_df = pd.DataFrame(result)\n",
    "result_df.columns =['Id','Label']\n",
    "result_df.to_csv(\"test_y_predict.csv\",header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
